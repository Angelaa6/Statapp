{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57379247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/site-packages (2.0.0)\n",
      "Requirement already satisfied: pytorch-forecasting in /usr/local/lib/python3.12/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.12/site-packages (from pytorch-lightning) (2.2.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/site-packages (from pytorch-lightning) (2.7.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/site-packages (from pytorch-lightning) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.12/site-packages (from pytorch-lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.12/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2025.3.2)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.12/site-packages (from pytorch-lightning) (1.7.1)\n",
      "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.12/site-packages (from pytorch-lightning) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/site-packages (from pytorch-lightning) (4.13.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.12/site-packages (from pytorch-lightning) (0.14.3)\n",
      "Requirement already satisfied: lightning<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/site-packages (from pytorch-forecasting) (2.5.1.post0)\n",
      "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.12/site-packages (from pytorch-forecasting) (1.15.2)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /usr/local/lib/python3.12/site-packages (from pytorch-forecasting) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.12/site-packages (from pytorch-forecasting) (1.6.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.11.18)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from lightning-utilities>=0.7.0->pytorch-lightning) (80.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/site-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/site-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.12/site-packages (from torch>=1.11.0->pytorch-lightning) (3.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.10)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch-forecasting) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-lightning pytorch-forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f815fa03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>inputTokenPriceUSD</th>\n",
       "      <th>accruedToTreasury</th>\n",
       "      <th>availableLiquidity</th>\n",
       "      <th>liquidityIndex</th>\n",
       "      <th>liquidityRate</th>\n",
       "      <th>stableBorrowRate</th>\n",
       "      <th>totalATokenSupply</th>\n",
       "      <th>totalCurrentVariableDebt</th>\n",
       "      <th>totalLiquidity</th>\n",
       "      <th>totalScaledVariableDebt</th>\n",
       "      <th>utilizationRate</th>\n",
       "      <th>variableBorrowIndex</th>\n",
       "      <th>variableBorrowRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-27 12:00:00+00:00</td>\n",
       "      <td>22901.415798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619864</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.619864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-27 13:00:00+00:00</td>\n",
       "      <td>22889.291609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.768670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-27 14:00:00+00:00</td>\n",
       "      <td>22840.819903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.443268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3.443268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.443268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-27 15:00:00+00:00</td>\n",
       "      <td>22979.545483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.263297</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>5.263297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.263297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-27 16:00:00+00:00</td>\n",
       "      <td>23008.788367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.318675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>5.318675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.318675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14018</th>\n",
       "      <td>2024-12-31 19:00:00+00:00</td>\n",
       "      <td>93759.525729</td>\n",
       "      <td>0.036288</td>\n",
       "      <td>33788.341342</td>\n",
       "      <td>1.003206</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36595.717590</td>\n",
       "      <td>2787.966074</td>\n",
       "      <td>36511.314003</td>\n",
       "      <td>2730.518880</td>\n",
       "      <td>0.074579</td>\n",
       "      <td>1.021039</td>\n",
       "      <td>0.003809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14019</th>\n",
       "      <td>2024-12-31 20:00:00+00:00</td>\n",
       "      <td>93759.525729</td>\n",
       "      <td>0.036469</td>\n",
       "      <td>33774.009561</td>\n",
       "      <td>1.003206</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36592.599123</td>\n",
       "      <td>2799.180682</td>\n",
       "      <td>36508.195222</td>\n",
       "      <td>2741.500825</td>\n",
       "      <td>0.074892</td>\n",
       "      <td>1.021040</td>\n",
       "      <td>0.003825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020</th>\n",
       "      <td>2024-12-31 21:00:00+00:00</td>\n",
       "      <td>93271.901873</td>\n",
       "      <td>0.037136</td>\n",
       "      <td>33746.943636</td>\n",
       "      <td>1.003206</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36583.706269</td>\n",
       "      <td>2817.354629</td>\n",
       "      <td>36499.301831</td>\n",
       "      <td>2759.298887</td>\n",
       "      <td>0.075409</td>\n",
       "      <td>1.021040</td>\n",
       "      <td>0.003823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14021</th>\n",
       "      <td>2024-12-31 22:00:00+00:00</td>\n",
       "      <td>93512.722731</td>\n",
       "      <td>0.038120</td>\n",
       "      <td>33746.963060</td>\n",
       "      <td>1.003206</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36583.727180</td>\n",
       "      <td>2817.356429</td>\n",
       "      <td>36499.321755</td>\n",
       "      <td>2759.299377</td>\n",
       "      <td>0.075408</td>\n",
       "      <td>1.021041</td>\n",
       "      <td>0.003851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14022</th>\n",
       "      <td>2024-12-31 23:00:00+00:00</td>\n",
       "      <td>93202.407034</td>\n",
       "      <td>0.038164</td>\n",
       "      <td>33743.807260</td>\n",
       "      <td>1.003206</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36580.616926</td>\n",
       "      <td>2817.402387</td>\n",
       "      <td>36496.210954</td>\n",
       "      <td>2759.343449</td>\n",
       "      <td>0.075416</td>\n",
       "      <td>1.021041</td>\n",
       "      <td>0.003851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14023 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       datetime  inputTokenPriceUSD  accruedToTreasury  \\\n",
       "0     2023-01-27 12:00:00+00:00        22901.415798           0.000000   \n",
       "1     2023-01-27 13:00:00+00:00        22889.291609           0.000000   \n",
       "2     2023-01-27 14:00:00+00:00        22840.819903           0.000000   \n",
       "3     2023-01-27 15:00:00+00:00        22979.545483           0.000000   \n",
       "4     2023-01-27 16:00:00+00:00        23008.788367           0.000000   \n",
       "...                         ...                 ...                ...   \n",
       "14018 2024-12-31 19:00:00+00:00        93759.525729           0.036288   \n",
       "14019 2024-12-31 20:00:00+00:00        93759.525729           0.036469   \n",
       "14020 2024-12-31 21:00:00+00:00        93271.901873           0.037136   \n",
       "14021 2024-12-31 22:00:00+00:00        93512.722731           0.038120   \n",
       "14022 2024-12-31 23:00:00+00:00        93202.407034           0.038164   \n",
       "\n",
       "       availableLiquidity  liquidityIndex  liquidityRate  stableBorrowRate  \\\n",
       "0                0.619864        1.000000       0.000000              0.09   \n",
       "1                0.768670        1.000000       0.000000              0.09   \n",
       "2                3.443268        1.000000       0.000000              0.09   \n",
       "3                5.263297        1.000000       0.000000              0.09   \n",
       "4                5.318675        1.000000       0.000000              0.09   \n",
       "...                   ...             ...            ...               ...   \n",
       "14018        33788.341342        1.003206       0.000145              0.00   \n",
       "14019        33774.009561        1.003206       0.000146              0.00   \n",
       "14020        33746.943636        1.003206       0.000146              0.00   \n",
       "14021        33746.963060        1.003206       0.000148              0.00   \n",
       "14022        33743.807260        1.003206       0.000148              0.00   \n",
       "\n",
       "       totalATokenSupply  totalCurrentVariableDebt  totalLiquidity  \\\n",
       "0               0.619864                  0.000000        0.619864   \n",
       "1               0.768670                  0.000000        0.768670   \n",
       "2               3.443268                  0.000000        3.443268   \n",
       "3               5.263297                  0.000000        5.263297   \n",
       "4               5.318675                  0.000000        5.318675   \n",
       "...                  ...                       ...             ...   \n",
       "14018       36595.717590               2787.966074    36511.314003   \n",
       "14019       36592.599123               2799.180682    36508.195222   \n",
       "14020       36583.706269               2817.354629    36499.301831   \n",
       "14021       36583.727180               2817.356429    36499.321755   \n",
       "14022       36580.616926               2817.402387    36496.210954   \n",
       "\n",
       "       totalScaledVariableDebt  utilizationRate  variableBorrowIndex  \\\n",
       "0                     0.000000         0.000000             1.000000   \n",
       "1                     0.000000         0.000000             1.000000   \n",
       "2                     0.000000         0.000000             1.000000   \n",
       "3                     0.000000         0.000000             1.000000   \n",
       "4                     0.000000         0.000000             1.000000   \n",
       "...                        ...              ...                  ...   \n",
       "14018              2730.518880         0.074579             1.021039   \n",
       "14019              2741.500825         0.074892             1.021040   \n",
       "14020              2759.298887         0.075409             1.021040   \n",
       "14021              2759.299377         0.075408             1.021041   \n",
       "14022              2759.343449         0.075416             1.021041   \n",
       "\n",
       "       variableBorrowRate  \n",
       "0                0.000000  \n",
       "1                0.000000  \n",
       "2                0.000000  \n",
       "3                0.000000  \n",
       "4                0.000000  \n",
       "...                   ...  \n",
       "14018            0.003809  \n",
       "14019            0.003825  \n",
       "14020            0.003823  \n",
       "14021            0.003851  \n",
       "14022            0.003851  \n",
       "\n",
       "[14023 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Hourly price\n",
    "\n",
    "data_2023 = [pd.read_csv(f\"Data/messari_hourly_prices/hourly_prices_2023_{i}.csv\", parse_dates=[\"datetime\"]) for i in range(1, 13)]\n",
    "data_2024 = [pd.read_csv(f\"Data/messari_hourly_prices/hourly_prices_2024_{i}.csv\", parse_dates=[\"datetime\"]) for i in range(1, 13)]\n",
    "df1 = pd.concat(data_2023 + data_2024).sort_values(\"datetime\").set_index(\"datetime\").drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "df1 = df1.reset_index()\n",
    "df1_btc = df1[df1['reserve_name']=='Wrapped BTC']\n",
    "\n",
    "# Reserves features\n",
    "\n",
    "data2_2023 = [pd.read_csv(f\"Data/reserves_features/reserves_history_hourly_completed_2023-{i}.csv\") for i in range(1, 13)]\n",
    "data2_2024 = [pd.read_csv(f\"Data/reserves_features/reserves_history_hourly_completed_2024-{i}.csv\") for i in range(1, 13)]\n",
    "dfr = pd.concat(data2_2023 + data2_2024).drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "dfr_btc = dfr[dfr['reserve_name']=='Wrapped BTC'].dropna().drop([\"totalPrincipalStableDebt\"], axis=1)\n",
    "\n",
    "# Merge\n",
    "\n",
    "dfr_btc['regular_datetime'] = pd.to_datetime(dfr_btc['regular_datetime'], utc=True)\n",
    "df_btc = pd.merge(df1_btc, dfr_btc, left_on='datetime', right_on='regular_datetime')\n",
    "df_btc = df_btc.drop(['blockNumber', 'timestamp_hours', 'id', 'snapshot_timestamp', \n",
    "'regular_datetime', 'reserve_name_x', 'reserve_name_y', 'reserve_pool', 'protocol', 'protocol_name', \n",
    "'priceInUsd', 'outputTokenPriceUSD', 'averageStableBorrowRate', 'priceInEth', 'reserve_decimals', \n",
    "'true_value', 'timestamp'], axis=1)\n",
    "\n",
    "df_btc = df_btc.sort_values(\"datetime\")\n",
    "df_btc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f2554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_forecasting as ptf\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.examples import get_stallion_data\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# df_btc['series_id'] = 'BTC'\n",
    "# df_btc[\"datetime\"] = df_btc.index.astype(\"int\")\n",
    "\n",
    "# # Define dataset\n",
    "# training = ptf.TimeSeriesDataSet(\n",
    "#     df_btc,\n",
    "#     time_idx='datetime',          # Timestamp column\n",
    "#     target='inputTokenPriceUSD',           # Target variable\n",
    "#     group_ids = ['series_id'], \n",
    "#     # static_categoricals=[],       # Metadata (e.g., asset type)\n",
    "#     time_varying_known_reals=[\n",
    "#         'accruedToTreasury','availableLiquidity', 'liquidityIndex', 'liquidityRate','stableBorrowRate', \n",
    "#         'totalATokenSupply','totalCurrentVariableDebt', 'totalLiquidity', 'totalScaledVariableDebt',\n",
    "#         'utilizationRate', 'variableBorrowIndex', 'variableBorrowRate'\n",
    "#     ],\n",
    "#     time_varying_unknown_reals=['inputTokenPriceUSD'],\n",
    "#     max_encoder_length=24,        # Lookback window (e.g., 24 hours)\n",
    "#     max_prediction_length=12,     # Forecast horizon (e.g., 12 hours)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b8840a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TemporalFusionTransformer.from_dataset(training)\n",
    "\n",
    "# trainer = Trainer(max_epochs=20)\n",
    "# train_dataloader = training.to_dataloader(train=True, batch_size=64, num_workers=4)\n",
    "# trainer.fit(model, train_dataloader)\n",
    "\n",
    "\n",
    "# # Initialize\n",
    "# tft = TemporalFusionTransformer.from_dataset(\n",
    "#     training,\n",
    "#     hidden_size=32,               # Model capacity\n",
    "#     lstm_layers=2,                # Depth of LSTM\n",
    "#     attention_head_size=4,        # Multi-head attention\n",
    "#     dropout=0.1,\n",
    "# )\n",
    "\n",
    "# # Train\n",
    "# trainer = pl.Trainer(max_epochs=10)\n",
    "# trainer.fit(tft, datamodule=training.to_dataloader(train=True, batch_size=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413467c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/usr/local/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'prepare_data_per_node'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Train with PyTorch Lightning\u001b[39;00m\n\u001b[32m     84\u001b[39m trainer = pl.Trainer(max_epochs=\u001b[32m10\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:520\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    518\u001b[39m model = _maybe_unwrap_optimized(model)\n\u001b[32m    519\u001b[39m \u001b[38;5;28mself\u001b[39m.strategy._lightning_module = model\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:44\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     42\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     47\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:559\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    549\u001b[39m \u001b[38;5;28mself\u001b[39m._data_connector.attach_data(\n\u001b[32m    550\u001b[39m     model, train_dataloaders=train_dataloaders, val_dataloaders=val_dataloaders, datamodule=datamodule\n\u001b[32m    551\u001b[39m )\n\u001b[32m    553\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    554\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    555\u001b[39m     ckpt_path,\n\u001b[32m    556\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    557\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    558\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    562\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:887\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[32m    886\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: preparing data\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_connector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    890\u001b[39m \u001b[38;5;66;03m# SET UP THE TRAINER\u001b[39;00m\n\u001b[32m    891\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    892\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: setting up strategy environment\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:92\u001b[39m, in \u001b[36m_DataConnector.prepare_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# handle datamodule prepare data:\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# check for prepare_data_per_node & datamodule lifecycle properties before calling datamodule.prepare_data\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datamodule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     dm_prepare_data_per_node = \u001b[43mdatamodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare_data_per_node\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (dm_prepare_data_per_node \u001b[38;5;129;01mand\u001b[39;00m local_rank_zero) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m dm_prepare_data_per_node \u001b[38;5;129;01mand\u001b[39;00m global_rank_zero):\n\u001b[32m     94\u001b[39m         call._call_lightning_datamodule_hook(trainer, \u001b[33m\"\u001b[39m\u001b[33mprepare_data\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataLoader' object has no attribute 'prepare_data_per_node'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "\n",
    "# 1. Load data\n",
    "data = get_stallion_data()\n",
    "\n",
    "data[\"date\"] = pd.to_datetime(np.array(data[\"date\"]))\n",
    "data[\"month\"] = data[\"date\"].dt.month\n",
    "data[\"year\"] = data[\"date\"].dt.year\n",
    "data[\"time_idx\"] = data[\"month\"] + 12 * (data[\"year\"] - data[\"year\"].min())\n",
    "\n",
    "\n",
    "# 2. Create dataset\n",
    "max_encoder_length = 36\n",
    "max_prediction_length = 6\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[data.time_idx <= 36 * 3],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"volume\",\n",
    "    group_ids=[\"agency\", \"sku\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_known_reals=[\"time_idx\", \"price_regular\", \"price_actual\"],\n",
    "    time_varying_unknown_reals=[\"volume\"],\n",
    "    static_categoricals=[\"agency\", \"sku\"],\n",
    ")\n",
    "\n",
    "# 3. Create dataloaders\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=64, num_workers=0)\n",
    "val_dataloader = training.to_dataloader(train=False, batch_size=64, num_workers=0)\n",
    "\n",
    "# 4. Create model — THIS is where your error likely came from\n",
    "model = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# # 5. Fit with Lightning Trainer\n",
    "# # trainer = Trainer(max_epochs=20, gradient_clip_val=0.1)\n",
    "# # trainer.fit(model, train_dataloader, val_dataloader)\n",
    "\n",
    "# import pytorch_lightning as pl\n",
    "# from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "\n",
    "# # Define a LightningModule wrapper for TFT\n",
    "# class TFTModel(pl.LightningModule):\n",
    "#     def __init__(self, tft):\n",
    "#         super().__init__()\n",
    "#         self.tft = tft\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         x, y = batch\n",
    "#         y_hat = self.tft(x)\n",
    "#         loss = self.tft.loss(y_hat, y)\n",
    "#         self.log(\"train_loss\", loss)\n",
    "#         return loss\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         return self.tft.configure_optimizers()\n",
    "\n",
    "# # Initialize TFT\n",
    "# tft = TemporalFusionTransformer.from_dataset(\n",
    "#     training,\n",
    "#     hidden_size=32,\n",
    "#     lstm_layers=2,\n",
    "#     attention_head_size=4,\n",
    "#     dropout=0.1,\n",
    "# )\n",
    "\n",
    "# # Wrap TFT in LightningModule\n",
    "# model = TFTModel(tft)\n",
    "\n",
    "# # Train with PyTorch Lightning\n",
    "# trainer = pl.Trainer(max_epochs=10)\n",
    "# trainer.fit(model, datamodule=training.to_dataloader(train=True, batch_size=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61e684d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tft.configure_optimizers()\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# 3. Initialize and train\u001b[39;00m\n\u001b[32m     42\u001b[39m validation = TimeSeriesDataSet.from_dataset(\n\u001b[32m     43\u001b[39m     training,\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[43mvalidation_data\u001b[49m,\n\u001b[32m     45\u001b[39m     predict=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     46\u001b[39m     stop_randomization=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     47\u001b[39m )\n\u001b[32m     49\u001b[39m datamodule = TFTDataModule(training, validation)\n\u001b[32m     50\u001b[39m model = TFTModel(tft)\n",
      "\u001b[31mNameError\u001b[39m: name 'validation_data' is not defined"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.core.datamodule import LightningDataModule\n",
    "\n",
    "# 1. Data Module\n",
    "class TFTDataModule(LightningDataModule):\n",
    "    def __init__(self, train_ds, val_ds, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.train_ds = train_ds\n",
    "        self.val_ds = val_ds\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return self.train_ds.to_dataloader(train=True, batch_size=self.batch_size)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.val_ds.to_dataloader(train=False, batch_size=self.batch_size)\n",
    "\n",
    "# 2. Model Wrapper (as before)\n",
    "class TFTModel(pl.LightningModule):\n",
    "    def __init__(self, tft):\n",
    "        super().__init__()\n",
    "        self.tft = tft\n",
    "        self.save_hyperparameters(ignore=['tft'])\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.tft(x)\n",
    "        loss = self.tft.loss(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.tft(x)\n",
    "        loss = self.tft.loss(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.tft.configure_optimizers()\n",
    "\n",
    "# 3. Initialize and train\n",
    "validation = TimeSeriesDataSet.from_dataset(\n",
    "    training,\n",
    "    validation_data,\n",
    "    predict=True,\n",
    "    stop_randomization=True\n",
    ")\n",
    "\n",
    "datamodule = TFTDataModule(training, validation)\n",
    "model = TFTModel(tft)\n",
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c07a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154f024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2de6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
